training:
  name: "local_2_10_1e-1_4"
  total_timesteps: 10000000 # Total number of training timesteps
  log_interval: 100 # Number of timesteps between logging events
  check_freq: 1000 # Number of timesteps between saving events
  judgment_timestep: 500000 # Number of timesteps before agent is able to say if position is reachable or not

SAC: # Soft Actor Critic parameters
  model_param:
    {
      policy: "MultiInputPolicy",
      verbose: 2,
      learning_starts: 1000,
      tensorboard_log: "logs/",
      device: "cpu",
      buffer_size: 1000000,
      learning_rate: 0.0003,
      train_freq: 2,
      gamma: 0.95,
      batch_size: 128,
      tau: 0.01,
      gradient_steps: 1,
      ent_coef: "auto_0.04",
      policy_kwargs: {
        net_arch: [512, 512, 512],
      },
    }
  HerReplayBuffer_param: # Added the HER replay buffer if wanted
    replay_buffer_kwargs:
      {
        copy_info_dict: True,
        n_sampled_goal: 1,
        goal_selection_strategy: "future",
      }


environment:
  nb_environments: 10 # Number of environments used to collect data
  has_judgment: True # If True, the agent will be able to say if a position is reachable or not after judgment_timestep steps(cf training)
  numSimulationSteps: 10 # Number of simulation steps between each action
  timeStepSimulation: 1e-3 # Time step of the simulation
  normalizeObs: True # Normalize the observation
  randomInit: True # Choose to randomize the position of controlled joint arount the initial position
  limitPosScale: 1 # Scale the position of the robot
  limitVelScale: 1 # Scale the velocity of the robot
  torqueScaleCoeff: 1 # Scale the torque applied to the robot
  thresholdSuccess: 0.05 # Distance to target to consider the task as a success
  timeSuccess: 2500 # Necessary time on target to consider the task as a success

  # Stop conditions
  maxTime: 300 # Maximum epoch time in seconds
  lowerLimitPos: [-0.25, -0.05, 0.9]
  upperLimitPos: [0.1, 0.05, 1.3]
  targetType: "sphere" # "fixed", "box" or "sphere"
  targetPosition: [0.4, 0.3, 1.05] # Position of the target
  targetSizeLow: [-0.1, -0.1, -0.1]  # Lower size of the target if box around position
  targetSizeHigh: [0.1, 0.1, 0.1] # Higher size of the target if box around position
  targetRadius: 0.1 # Radius of the target if sphere around position

  rewardType: "mix" # "sparse", "dense" or "mix" if want to mix both
  w_target_reached: 1 # Coeff of boolean reward : 1 if target reached, 0 otherwise times w_target_reached
  w_target_pos: 20 # Coeff of distance reward : - distance to target times w_target_pos
  w_control_reg: 0.07 # Coeff of torque reward : - torques times w_control_reg
  w_penalization_truncation: 7 # Coeff of velocity reward : 1 if alive else 0 times w_penalization_truncation
  w_joints_to_init: # truncation coeff for each joint, if not in dictionary, no penalization
    torso_1_joint: 0.1
    torso_2_joint: 0.1


robot_designer:
  URDF: "/talos_data/robots/talos_reduced.urdf"
  SRDF: "/talos_data/srdf/talos.srdf"
  controlledJoints:
    [
      # root_joint,
      # leg_left_1_joint,
      # leg_left_2_joint,
      # leg_left_3_joint,
      # leg_left_4_joint,
      # leg_left_5_joint,
      # leg_left_6_joint,
      # leg_right_1_joint,
      # leg_right_2_joint,
      # leg_right_3_joint,
      # leg_right_4_joint,
      # leg_right_5_joint,
      # leg_right_6_joint,
      torso_1_joint,
      torso_2_joint,
      arm_left_1_joint,
      arm_left_2_joint,
      arm_left_3_joint,
      arm_left_4_joint,
      arm_left_5_joint,
      arm_left_6_joint,
      arm_left_7_joint,
      # arm_right_1_joint,
      # arm_right_2_joint,
      # arm_right_3_joint,
      # arm_right_4_joint,
    ]

  # Shape of the robot tool
  toolPosition: [0, -0.02, -0.0825]

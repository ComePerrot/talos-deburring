training:
  name: "local_training"
  total_timesteps: 10000000 # Total number of training timesteps
  log_interval: 100 # Number of timesteps between logging events
  check_freq: 1000 # Number of timesteps between saving events

SAC:
  model_param:
    {
      policy: "MultiInputPolicy",
      verbose: 2,
      learning_starts: 1000,
      tensorboard_log: "logs/",
      device: "cpu",
      buffer_size: 1000000,
      learning_rate: 0.0003,
      train_freq: 2, # [2, "step"],
      gradient_steps: 1,
      gamma: 0.95,
      batch_size: 128,
      tau: 0.01,
      ent_coef: "auto_0.04",
      policy_kwargs: {
        net_arch: [512, 512, 512],
      },
    }
  HerReplayBuffer_param:
    replay_buffer_kwargs:
      {
        copy_info_dict: True,
        n_sampled_goal: 1,
        goal_selection_strategy: "future",
      }


environment:
  nb_environments: 10 # Number of environments used to collect data
  numSimulationSteps: 10
  timeStepSimulation: 1e-3
  normalizeObs: False
  randomInit: True # Choose to randomize the position of controlled joint arount the initial position 
  limitPosScale: 1
  limitVelScale: 1
  torqueScaleCoeff: 1
  thresholdSuccess: 0.01

  # Stop conditions
  maxTime: 30 # Maximum epoch time in seconds
  lowerLimitPos: [-0.25, -0.05, 0.9]
  upperLimitPos: [0.1, 0.05, 1.3]
  # Target (can be a fixed position or a box or a sphere)
  targetType: "box"
  # if fixed position only this parameter is used
  targetPosition: [0.4, 0.3, 1.05]
  # if box, around the targetPosition
  targetSizeLow: [-0.1, -0.1, -0.1]
  targetSizeHigh: [0.1, 0.1, 0.1]
  # if sphere, around the targetPosition
  targetRadius: 0.2
  
  rewardType: "mix" # "sparse", "dense" or "mix" if want to mix both
  # Currently, w_target_reached does not seems to work if not 0 (TO check), so equivalent to dense rn
  # Coeff of boolean reward : 1 if target reached, 0 otherwise times w_target_reached
  w_target_reached: 0
  # Coeff of distance reward : - distance to target times w_target_pos
  w_target_pos: 30
  # Coeff of torque reward : - torques times w_control_reg
  w_control_reg: 0.1
  # Coeff of velocity reward : 1 if alive else 0 times w_penalization_truncation
  w_penalization_truncation: 4


robot_designer:
  URDF: "/talos_data/robots/talos_reduced.urdf"
  SRDF: "/talos_data/srdf/talos.srdf"
  controlledJoints:
    [
      # root_joint,
      # leg_left_1_joint,
      # leg_left_2_joint,
      # leg_left_3_joint,
      # leg_left_4_joint,
      # leg_left_5_joint,
      # leg_left_6_joint,
      # leg_right_1_joint,
      # leg_right_2_joint,
      # leg_right_3_joint,
      # leg_right_4_joint,
      # leg_right_5_joint,
      # leg_right_6_joint,
      torso_1_joint,
      torso_2_joint,
      arm_left_1_joint,
      arm_left_2_joint,
      arm_left_3_joint,
      arm_left_4_joint,
      arm_left_5_joint,
      arm_left_6_joint,
      arm_left_7_joint,
      # arm_right_1_joint,
      # arm_right_2_joint,
      # arm_right_3_joint,
      # arm_right_4_joint,
    ]

  # Initial position of the robot
  toolPosition: [0, -0.02, -0.0825]